Sammy@HQQ MINGW64 ~/repos/CSMC_35200_BraintoTextGroup/neural_seq_decoder (master)
$ python ./scripts/train_model.py
C:\Users\Sammy\AppData\Roaming\Python\Python312\site-packages\torch\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\TensorShape.cpp:4324.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
C:\Users\Sammy\repos\CSMC_35200_BraintoTextGroup\neural_seq_decoder\src\neural_decoder\augmentations.py:91: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\Convolution.cpp:1028.)
  return self.conv(input, weight=self.weight, groups=self.groups, padding="same")
C:\Users\Sammy\repos\CSMC_35200_BraintoTextGroup\neural_seq_decoder\src\neural_decoder\neural_decoder_trainer.py:177: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),
batch 0, ctc loss: 5.912408, cer: 0.961537, time/batch:   0.074
batch 100, ctc loss: 2.828450, cer: 0.820106, time/batch:   0.303
batch 200, ctc loss: 2.463204, cer: 0.703685, time/batch:   0.316
batch 300, ctc loss: 2.245719, cer: 0.618546, time/batch:   0.324
batch 400, ctc loss: 2.062904, cer: 0.571953, time/batch:   0.333
batch 500, ctc loss: 1.970159, cer: 0.537617, time/batch:   0.347
batch 600, ctc loss: 1.886602, cer: 0.509265, time/batch:   0.351
batch 700, ctc loss: 1.801139, cer: 0.497256, time/batch:   0.914
batch 800, ctc loss: 1.743017, cer: 0.480830, time/batch:   0.597
batch 900, ctc loss: 1.672436, cer: 0.470430, time/batch:   0.592
batch 1000, ctc loss: 1.609295, cer: 0.449837, time/batch:   0.593
batch 1100, ctc loss: 1.551149, cer: 0.422021, time/batch:   0.594
batch 1200, ctc loss: 1.516098, cer: 0.416739, time/batch:   0.590
batch 1300, ctc loss: 1.454655, cer: 0.401841, time/batch:   0.686
batch 1400, ctc loss: 1.410967, cer: 0.385044, time/batch:   0.605
batch 1500, ctc loss: 1.378306, cer: 0.378523, time/batch:   0.597
batch 1600, ctc loss: 1.361580, cer: 0.371755, time/batch:   0.580
batch 1700, ctc loss: 1.330856, cer: 0.366349, time/batch:   0.592
batch 1800, ctc loss: 1.288996, cer: 0.358095, time/batch:   0.588
batch 1900, ctc loss: 1.297570, cer: 0.354752, time/batch:   0.583
batch 2000, ctc loss: 1.256158, cer: 0.349016, time/batch:   0.571
batch 2100, ctc loss: 1.256209, cer: 0.344806, time/batch:   0.583
batch 2200, ctc loss: 1.240021, cer: 0.338244, time/batch:   0.601
batch 2300, ctc loss: 1.198726, cer: 0.330527, time/batch:   0.605
batch 2400, ctc loss: 1.171754, cer: 0.325781, time/batch:   0.573
batch 2500, ctc loss: 1.166865, cer: 0.321902, time/batch:   0.576
batch 2600, ctc loss: 1.143521, cer: 0.323057, time/batch:   0.564
batch 2700, ctc loss: 1.138753, cer: 0.315422, time/batch:   0.319
batch 2800, ctc loss: 1.125099, cer: 0.311832, time/batch:   0.580
batch 2900, ctc loss: 1.124241, cer: 0.307788, time/batch:   0.581
batch 3000, ctc loss: 1.109959, cer: 0.307540, time/batch:   0.585
batch 3100, ctc loss: 1.099524, cer: 0.303867, time/batch:   0.573
batch 3200, ctc loss: 1.087563, cer: 0.303248, time/batch:   0.571
batch 3300, ctc loss: 1.079309, cer: 0.301391, time/batch:   0.586
batch 3400, ctc loss: 1.068829, cer: 0.297264, time/batch:   0.574
batch 3500, ctc loss: 1.059383, cer: 0.295118, time/batch:   0.583
batch 3600, ctc loss: 1.042631, cer: 0.287318, time/batch:   0.574
batch 3700, ctc loss: 1.021649, cer: 0.284388, time/batch:   0.586
batch 3800, ctc loss: 1.035749, cer: 0.287442, time/batch:   0.574
batch 3900, ctc loss: 1.016199, cer: 0.280013, time/batch:   0.323
batch 4000, ctc loss: 1.002348, cer: 0.278115, time/batch:   0.577
batch 4100, ctc loss: 1.007671, cer: 0.278032, time/batch:   0.580
batch 4200, ctc loss: 1.008451, cer: 0.283521, time/batch:   0.589
batch 4300, ctc loss: 0.994933, cer: 0.275515, time/batch:   0.333
batch 4400, ctc loss: 0.993530, cer: 0.277207, time/batch:   0.594
batch 4500, ctc loss: 0.973310, cer: 0.269036, time/batch:   0.330
batch 4600, ctc loss: 0.977337, cer: 0.269613, time/batch:   0.592
batch 4700, ctc loss: 0.963974, cer: 0.270686, time/batch:   0.336
batch 4800, ctc loss: 0.944244, cer: 0.261731, time/batch:   0.329
batch 4900, ctc loss: 0.942469, cer: 0.263712, time/batch:   0.595
batch 5000, ctc loss: 0.947417, cer: 0.260740, time/batch:   0.343
batch 5100, ctc loss: 0.958745, cer: 0.263794, time/batch:   0.583
batch 5200, ctc loss: 0.951944, cer: 0.263753, time/batch:   0.334
batch 5300, ctc loss: 0.944441, cer: 0.261566, time/batch:   0.336
batch 5400, ctc loss: 0.933681, cer: 0.256737, time/batch:   0.335
batch 5500, ctc loss: 0.934672, cer: 0.257521, time/batch:   0.588
batch 5600, ctc loss: 0.918632, cer: 0.254880, time/batch:   0.331
batch 5700, ctc loss: 0.921637, cer: 0.257521, time/batch:   0.579
batch 5800, ctc loss: 0.927673, cer: 0.255458, time/batch:   0.336
batch 5900, ctc loss: 0.917201, cer: 0.251537, time/batch:   0.334
batch 6000, ctc loss: 0.918233, cer: 0.257026, time/batch:   0.592
batch 6100, ctc loss: 0.901049, cer: 0.252074, time/batch:   0.319
batch 6200, ctc loss: 0.898502, cer: 0.251455, time/batch:   0.328
batch 6300, ctc loss: 0.887953, cer: 0.245429, time/batch:   0.571
batch 6400, ctc loss: 0.895999, cer: 0.245842, time/batch:   0.587
batch 6500, ctc loss: 0.894621, cer: 0.245182, time/batch:   0.329
batch 6600, ctc loss: 0.894897, cer: 0.246214, time/batch:   0.581
batch 6700, ctc loss: 0.887160, cer: 0.244480, time/batch:   0.323
batch 6800, ctc loss: 0.906958, cer: 0.250258, time/batch:   0.576
batch 6900, ctc loss: 0.898229, cer: 0.247823, time/batch:   0.326
batch 7000, ctc loss: 0.874173, cer: 0.241674, time/batch:   0.333
batch 7100, ctc loss: 0.876394, cer: 0.236887, time/batch:   0.579
batch 7200, ctc loss: 0.892985, cer: 0.241674, time/batch:   0.573
batch 7300, ctc loss: 0.887727, cer: 0.244068, time/batch:   0.321
batch 7400, ctc loss: 0.900929, cer: 0.244728, time/batch:   0.337
batch 7500, ctc loss: 0.886304, cer: 0.239280, time/batch:   0.338
batch 7600, ctc loss: 0.881841, cer: 0.239363, time/batch:   0.334
batch 7700, ctc loss: 0.873751, cer: 0.236928, time/batch:   0.334
batch 7800, ctc loss: 0.879497, cer: 0.236309, time/batch:   0.342
batch 7900, ctc loss: 0.891224, cer: 0.235525, time/batch:   0.591
batch 8000, ctc loss: 0.873294, cer: 0.237423, time/batch:   0.583
batch 8100, ctc loss: 0.862965, cer: 0.229458, time/batch:   0.330
batch 8200, ctc loss: 0.888476, cer: 0.237464, time/batch:   0.582
batch 8300, ctc loss: 0.890575, cer: 0.234741, time/batch:   0.331
batch 8400, ctc loss: 0.870184, cer: 0.232883, time/batch:   0.336
batch 8500, ctc loss: 0.879154, cer: 0.231439, time/batch:   0.351
batch 8600, ctc loss: 0.875334, cer: 0.231522, time/batch:   0.342
batch 8700, ctc loss: 0.866060, cer: 0.230366, time/batch:   0.336
batch 8800, ctc loss: 0.867899, cer: 0.232842, time/batch:   0.343
batch 8900, ctc loss: 0.870818, cer: 0.232347, time/batch:  41.986
batch 9000, ctc loss: 0.862082, cer: 0.231810, time/batch:   0.285
batch 9100, ctc loss: 0.864908, cer: 0.230118, time/batch:   0.291
batch 9200, ctc loss: 0.851486, cer: 0.227560, time/batch:   0.300
batch 9300, ctc loss: 0.858235, cer: 0.226404, time/batch:   0.298
batch 9400, ctc loss: 0.857677, cer: 0.226899, time/batch:   0.306
batch 9500, ctc loss: 0.849530, cer: 0.225001, time/batch:   0.296
batch 9600, ctc loss: 0.855261, cer: 0.225703, time/batch:   0.314
batch 9700, ctc loss: 0.851606, cer: 0.224258, time/batch:   0.309
batch 9800, ctc loss: 0.875888, cer: 0.226858, time/batch:   0.321
batch 9900, ctc loss: 0.864270, cer: 0.226198, time/batch:   0.308